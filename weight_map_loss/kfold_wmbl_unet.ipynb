{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import argparse\r\n",
    "import os\r\n",
    "\r\n",
    "import cv2\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from keras import backend as K\r\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\r\n",
    "from keras.layers import Activation, BatchNormalization, Dropout, Input\r\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\r\n",
    "from keras.layers.core import Reshape\r\n",
    "from keras.layers.merge import add, concatenate\r\n",
    "from keras.layers.pooling import MaxPooling2D\r\n",
    "from keras.models import Model\r\n",
    "from tensorflow.keras.optimizers import SGD\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from sklearn.model_selection import KFold, train_test_split\r\n",
    "\r\n",
    "from helpers import adjust_brightness, Metrics, cw_map_loss, generate_class_weighted_maps, generate_weight_maps\r\n",
    "plt.style.use(\"ggplot\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "K.James 2019\r\n",
    " Trains a U-Net model using k-fold validation. \r\n",
    " This code used for MSc thesis and paper in various configurations.\r\n",
    "\r\n",
    "Arguments: \r\n",
    " -w : weight map weights\r\n",
    " -t : weight map edge thickness\r\n",
    "\r\n",
    "Images in paths: path_train = 'unet_data_new\\\\' and  path_test = 'unet_data_new\\\\test\\\\'\r\n",
    "Expects images to be in 'images' folder and corresponding masks to be in 'masks' folder within each of these paths\r\n",
    "Please create folder structure kfold\\output for the outputs.\r\n",
    "\r\n",
    "References: \r\n",
    " U-Net: O. Ronneberger, P. Fischer, and T.Brox, \"U-Net: Convolutional netowrks for biomedical image segmentation,\" \r\n",
    " in International Conference on Meidcal image computing and computer-assisted intervention. \r\n",
    " Springer, 2015, pp.234-241\r\n",
    "\r\n",
    "Acknowledgements: U-Net implementation based on:  https://www.depends-on-the-definition.com/unet-keras-segmenting-images/ (has MIT license)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get and resize images and masks\r\n",
    "def get_data(path, load_masks=True):  \r\n",
    "    ids = os.listdir(path + \"images\") \r\n",
    "    idsmasks  = os.listdir(path + \"masks\")  \r\n",
    "    l = len(ids)       \r\n",
    "    \r\n",
    "    X = np.zeros((l, im_height, im_width, 3), dtype=np.float32)\r\n",
    "   \r\n",
    "    if load_masks:\r\n",
    "        y = np.zeros((l, im_height, im_width, 1), dtype=np.float32)        \r\n",
    "    print('Getting and resizing images ... ')\r\n",
    "    for i in range(l):  \r\n",
    "        \r\n",
    "        image = cv2.imread(path + \"images\\\\\" + ids[i])      \r\n",
    "        x_img = cv2.resize(image,(im_height, im_width))\r\n",
    "                    \r\n",
    "        \r\n",
    "        if load_masks:               \r\n",
    "            mask = cv2.imread(path + 'masks\\\\' + idsmasks[i],0)\r\n",
    "            mask = cv2.resize(mask,(im_height, im_width))\r\n",
    "            ret,mask = cv2.threshold(mask,127,255,cv2.THRESH_BINARY) #thresh to fix any px that arent quite 1 or 0 after resize\r\n",
    "            mask = mask.reshape((im_height, im_width,1))\r\n",
    "\r\n",
    "        X[i] = x_img.squeeze() / 255\r\n",
    "       \r\n",
    "        if load_masks:\r\n",
    "            y[i] = mask / 255\r\n",
    "    print('Done!')\r\n",
    "    if load_masks:\r\n",
    "        return X, y\r\n",
    "    else:\r\n",
    "        return X\r\n",
    "\r\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\r\n",
    "    # first layer\r\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\r\n",
    "               padding=\"same\")(input_tensor)\r\n",
    "    if batchnorm:\r\n",
    "        x = BatchNormalization()(x)\r\n",
    "    x = Activation(\"relu\")(x)\r\n",
    "    # second layer\r\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\r\n",
    "               padding=\"same\")(x)\r\n",
    "    if batchnorm:\r\n",
    "        x = BatchNormalization()(x)\r\n",
    "    x = Activation(\"relu\")(x)\r\n",
    "    return x\r\n",
    "\r\n",
    "def get_weightmap_unet(n_filters=16, dropout=0.5, batchnorm=True):\r\n",
    "    \r\n",
    "    input_img = Input((im_height, im_width, 3), name='img')\r\n",
    "    weight_map_ip = Input((im_height, im_width,1),name='map')   \r\n",
    "    \r\n",
    "    # contracting path\r\n",
    "    \r\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\r\n",
    "    p1 = MaxPooling2D((2, 2)) (c1) #stride defaults to poolsize, ie, 2.\r\n",
    "    p1 = Dropout(dropout*0.5)(p1)\r\n",
    "\r\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\r\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\r\n",
    "    p2 = Dropout(dropout)(p2)\r\n",
    "\r\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\r\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\r\n",
    "    p3 = Dropout(dropout)(p3)\r\n",
    "\r\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\r\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\r\n",
    "    p4 = Dropout(dropout)(p4)\r\n",
    "    \r\n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\r\n",
    "    \r\n",
    "    # expansive path   \r\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\r\n",
    "    u6 = concatenate([u6, c4])\r\n",
    "    u6 = Dropout(dropout)(u6)\r\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\r\n",
    "\r\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\r\n",
    "    u7 = concatenate([u7, c3])\r\n",
    "    u7 = Dropout(dropout)(u7)\r\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\r\n",
    "\r\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\r\n",
    "    u8 = concatenate([u8, c2])\r\n",
    "    u8 = Dropout(dropout)(u8)\r\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\r\n",
    "\r\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\r\n",
    "    u9 = concatenate([u9, c1], axis=3)\r\n",
    "    u9 = Dropout(dropout)(u9)\r\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\r\n",
    "    \r\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid',name=\"output\") (c9)\r\n",
    "\r\n",
    "    model = Model(inputs=[input_img,weight_map_ip], outputs=[outputs,weight_map_ip]) #pass weight map straight from input to output\r\n",
    "    #print(model.summary())\r\n",
    "    print('MODEL INPUT',model.input_shape)\r\n",
    "    print(\"MODEL OUTPUT\",model.output_shape)   \r\n",
    "    \r\n",
    "    return model\r\n",
    "\r\n",
    "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\r\n",
    "    # contracting path\r\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\r\n",
    "    p1 = MaxPooling2D((2, 2)) (c1) #stride defaults to poolsize, ie, 2.\r\n",
    "    p1 = Dropout(dropout*0.5)(p1)\r\n",
    "\r\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\r\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\r\n",
    "    p2 = Dropout(dropout)(p2)\r\n",
    "\r\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\r\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\r\n",
    "    p3 = Dropout(dropout)(p3)\r\n",
    "\r\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\r\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\r\n",
    "    p4 = Dropout(dropout)(p4)\r\n",
    "    \r\n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\r\n",
    "    \r\n",
    "    # expansive path   \r\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\r\n",
    "    u6 = concatenate([u6, c4])\r\n",
    "    u6 = Dropout(dropout)(u6)\r\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\r\n",
    "\r\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\r\n",
    "    u7 = concatenate([u7, c3])\r\n",
    "    u7 = Dropout(dropout)(u7)\r\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\r\n",
    "\r\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\r\n",
    "    u8 = concatenate([u8, c2])\r\n",
    "    u8 = Dropout(dropout)(u8)\r\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\r\n",
    "\r\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\r\n",
    "    u9 = concatenate([u9, c1], axis=3)\r\n",
    "    u9 = Dropout(dropout)(u9)\r\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\r\n",
    "    \r\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)    \r\n",
    "\r\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\r\n",
    "  \r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#   Arguments\r\n",
    "ap = argparse.ArgumentParser()\r\n",
    "ap.add_argument(\"-w\", \"--weights\", type=str, default=\"2,0.5\")\r\n",
    "ap.add_argument(\"-t\", \"--thick\", type=int, default=5)\r\n",
    "args = vars(ap.parse_args())\r\n",
    "\r\n",
    "weights =list(map(float,args[\"weights\"].split(',')))\r\n",
    "\r\n",
    "# Set some parameters\r\n",
    "im_width = 512\r\n",
    "im_height = 512\r\n",
    "border = 5\r\n",
    "path_train = 'unet_data_new\\\\'\r\n",
    "path_test = 'unet_data_new\\\\test\\\\'\r\n",
    "U = weights[0] #background\r\n",
    "L = weights[1] #edge\r\n",
    "t = args[\"thick\"]\r\n",
    "print(U,L,t)\r\n",
    "#F=weights[1]\r\n",
    "#L=weights[2]\r\n",
    "#------------------------------------------"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Train -------\r\n",
    "X, y = get_data(path_train, load_masks=True)\r\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42) #<----------------------------------------------------------------\r\n",
    "fold = 0\r\n",
    "overall_metrics = [[],[],[],[],[],[],[],[],[],[],[]]\r\n",
    "names = [\"precision\",\"recall\",\"F1\",\"Dice\",\"IOU\",\"Accuracy\",\"av_precision\",\"av_recall\",\"av_F1\",\"av_Dice\",\"av_IOU\"]\r\n",
    "#------------\r\n",
    "\r\n",
    "for train_indices, val_indices in kfold.split(X, y):\r\n",
    "    fold+=1\r\n",
    "    print(\"\\n \\n Fold {}\".format(fold))  \r\n",
    "\r\n",
    "    \r\n",
    "    print(train_indices.shape,val_indices.shape)\r\n",
    "    if(len(train_indices)%2 !=0):\r\n",
    "        train_indices = train_indices[:-1]\r\n",
    "    if(len(val_indices)%2 !=0):\r\n",
    "        val_indices = val_indices[:-1]\r\n",
    "    print(train_indices.shape,val_indices.shape)\r\n",
    "\r\n",
    "    X_train = X[train_indices]\r\n",
    "    y_train = y[train_indices]\r\n",
    "    X_valid = X[val_indices]\r\n",
    "    y_valid = y[val_indices] \r\n",
    "\r\n",
    "    w_train = generate_weight_maps(y_train,[U,L],t)    \r\n",
    "    w_train = np.expand_dims(w_train,3)\r\n",
    "\r\n",
    "    #w_valid = generate_class_weighted_maps(y_valid,[U,F,L],t) \r\n",
    "    w_valid = generate_weight_maps(y_valid,[U,L],t) \r\n",
    "    w_valid = np.expand_dims(w_valid,3)\r\n",
    "\r\n",
    "    print(len(X_train),len(X_valid))\r\n",
    "   \r\n",
    "    model = get_weightmap_unet( n_filters=16, dropout=0.05, batchnorm=True)\r\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\r\n",
    "    model.compile(optimizer=sgd, loss=cw_map_loss)\r\n",
    "    \r\n",
    "    \r\n",
    "    data_gen_args_image = dict(horizontal_flip=True,\r\n",
    "                        vertical_flip=True,\r\n",
    "                        rotation_range=20,\r\n",
    "                        width_shift_range=0.2,\r\n",
    "                        height_shift_range=0.2,\r\n",
    "                        zoom_range=0.2,\r\n",
    "                        fill_mode='nearest',\r\n",
    "                        preprocessing_function=adjust_brightness)\r\n",
    "\r\n",
    "    data_gen_args_mask = dict(horizontal_flip=True,\r\n",
    "                        vertical_flip=True,\r\n",
    "                        rotation_range=20,\r\n",
    "                        width_shift_range=0.2,\r\n",
    "                        height_shift_range=0.2,\r\n",
    "                        zoom_range=0.2,\r\n",
    "                        fill_mode='nearest'\r\n",
    "                        )\r\n",
    "   \r\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args_image)\r\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args_mask)\r\n",
    " \r\n",
    "    seed = 2019 #same seed for both as we have to distort mask in the same way\r\n",
    "    bs = 2\r\n",
    "\r\n",
    "      \r\n",
    "    #yields [X1i, X2i],yi\r\n",
    "    def generator():\r\n",
    "        image_generator = image_datagen.flow(X_train, seed=seed, batch_size=bs, shuffle=True)\r\n",
    "        mask_generator = mask_datagen.flow(y_train, seed=seed, batch_size=bs, shuffle=True)\r\n",
    "        weight_generator = mask_datagen.flow(w_train, seed=seed, batch_size=bs, shuffle=True)\r\n",
    "        while True:\r\n",
    "            X1i = image_generator.next()\r\n",
    "            X2i = weight_generator.next()                      \r\n",
    "            yi = mask_generator.next()    \r\n",
    "\r\n",
    "            # ---threshold arrays---keep them binary not interpolated\r\n",
    "\r\n",
    "            #Weights\r\n",
    "            M = (U-L)/2. + L\r\n",
    "            X2i[X2i < M] = L\r\n",
    "            X2i[X2i >= M] = U\r\n",
    "            \r\n",
    "            #Masks            \r\n",
    "            yi[yi < 0.5] = 0\r\n",
    "            yi[yi >= 0.5] = 1              \r\n",
    "            \r\n",
    "            yield ([X1i, X2i],[yi,X2i])\r\n",
    "   \r\n",
    "    callbacks = [\r\n",
    "        EarlyStopping(patience=20, verbose=1),\r\n",
    "        ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\r\n",
    "        ModelCheckpoint('kfold\\\\output\\\\model-hakea{}.h5'.format(fold), verbose=1, save_best_only=True, save_weights_only=True)\r\n",
    "    ]\r\n",
    "   \r\n",
    "    a =  [X_valid,w_valid]\r\n",
    "    b =  [y_valid,w_valid]     \r\n",
    "    results = model.fit_generator(generator(), steps_per_epoch=(len(X_train) // bs), epochs=2000, callbacks=callbacks, validation_data=(a,b))    \r\n",
    "    \r\n",
    "    plt.figure(figsize=(8, 8))\r\n",
    "    plt.title(\"Learning curve\")\r\n",
    "    plt.plot(results.history[\"loss\"], label=\"loss\")\r\n",
    "    plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\r\n",
    "    plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\r\n",
    "    plt.xlabel(\"epochs\")\r\n",
    "    plt.ylabel(\"loss\")\r\n",
    "    plt.legend()\r\n",
    "    plt.savefig('kfold\\\\output\\\\LearningCurve{}'.format(fold),bbox_inches='tight')\r\n",
    "\r\n",
    "    \r\n",
    "\r\n",
    "    #---------\r\n",
    "    input_img = Input((im_height, im_width, 3), name='img')\r\n",
    "    inference = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\r\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\r\n",
    "    inference.compile(optimizer=sgd, loss=\"binary_crossentropy\", metrics=['accuracy'])\r\n",
    "\r\n",
    "    inference.load_weights('kfold\\\\output\\\\model-hakea{}.h5'.format(fold))\r\n",
    "    \r\n",
    "    preds_val = inference.predict(X_valid, verbose=1)\r\n",
    "    \r\n",
    "    kernel = np.ones((5,5),np.uint8)\r\n",
    "    preds_val_t = (preds_val > 0.5).astype(np.uint8)\r\n",
    "    binary = []\r\n",
    "\r\n",
    "    #remove noise\r\n",
    "    for i in range(0,len(preds_val_t)):\r\n",
    "        im = preds_val_t[i]   \r\n",
    "        \r\n",
    "        im = cv2.morphologyEx(im, cv2.MORPH_OPEN, kernel)      \r\n",
    "            \r\n",
    "        binary.append(im)\r\n",
    "   \r\n",
    "           \r\n",
    "    \r\n",
    "    print('calculating metrics')\r\n",
    "    y_valid = y_valid.astype('uint8')\r\n",
    "    binary = np.array(binary)\r\n",
    "    binary = binary.astype('uint8')\r\n",
    "    \r\n",
    "    m = Metrics(y_valid.squeeze(),binary) \r\n",
    "    overall_metrics[0].append(m.precison(True))\r\n",
    "    overall_metrics[1].append(m.recall(True))\r\n",
    "    overall_metrics[2].append(m.f1_score(True))\r\n",
    "    overall_metrics[3].append(m.dice(True))\r\n",
    "    overall_metrics[4].append(m.iou(True))\r\n",
    "    overall_metrics[5].append(m.accuracy(True))\r\n",
    "    \r\n",
    "    overall_metrics[6].append(m.precison(False))\r\n",
    "    overall_metrics[7].append(m.recall(False))\r\n",
    "    overall_metrics[8].append(m.f1_score(False))\r\n",
    "    overall_metrics[9].append(m.dice(False))\r\n",
    "    overall_metrics[10].append(m.iou(False))    \r\n",
    "    \r\n",
    "    f = open(\"kfold\\\\output\\\\{}.txt\".format(fold),\"w+\")\r\n",
    "    f.write(\"           Batchwise,         Average\\n\")\r\n",
    "    f.write(\"Precision {:.2f} {:.2f}\\n\".format(m.precison(True),m.precison(False)))\r\n",
    "    f.write(\"Recall    {:.2f} {:.2f}\\n\".format(m.recall(True),m.recall(False)))\r\n",
    "    f.write(\"F1        {:.2f} {:.2f}\\n\".format(m.f1_score(True),m.f1_score(False)))\r\n",
    "    f.write(\"Dice      {:.2f} {:.2f}\\n\".format(m.dice(True),m.dice(False)))\r\n",
    "    f.write(\"IOU       {:.2f} {:.2f}\\n\".format(m.iou(True),m.iou(False)))\r\n",
    "    f.write(\"Accuracy  {:.2f}\\n\".format(m.accuracy()))\r\n",
    "    f.close()\r\n",
    "    \r\n",
    "    \r\n",
    "f = open(\"kfold\\\\output\\\\cumulative_results.txt\",\"w+\")\r\n",
    "\r\n",
    "print('-------------------------')\r\n",
    "print('-------------------------')\r\n",
    "for m in range(len(overall_metrics)):  \r\n",
    "        n = names[m]       \r\n",
    "        mean = np.array(overall_metrics[m])            \r\n",
    "        overall_metrics[m].append(np.mean(mean)) #add so we can take mean across the folds\r\n",
    "        stdev = np.std(overall_metrics[m])\r\n",
    "        print(\"{}: {:.2f} +- {:.2f}\".format(n,np.mean(mean),stdev))\r\n",
    "        f.write(\"{}: {:.2f} +- {:.2f}\\n\".format(n,np.mean(mean),stdev))\r\n",
    "\r\n",
    "print('-------------------------')\r\n",
    "print('-------------------------')\r\n",
    "f.close()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}