{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":4,"colab":{"name":"kfold_wmbl_unet.ipynb","provenance":[{"file_id":"https://github.com/MitchStares/DroneML/blob/master/weight_map_loss/kfold_wmbl_unet.ipynb","timestamp":1628811265379}],"collapsed_sections":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-DIZrJeatkon","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628813014161,"user_tz":-600,"elapsed":23929,"user":{"displayName":"Mitchell Stares","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVXqZWjE_TYBCDaTb8aUFX0KkvgDiMSNHzRC7xVw=s64","userId":"10987502777190906211"}},"outputId":"09c084c0-3b9b-480e-9d86-202bf592bf4e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1MMQ1UJuUxn","executionInfo":{"status":"ok","timestamp":1628813018694,"user_tz":-600,"elapsed":283,"user":{"displayName":"Mitchell Stares","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVXqZWjE_TYBCDaTb8aUFX0KkvgDiMSNHzRC7xVw=s64","userId":"10987502777190906211"}},"outputId":"94973e26-a9e1-44a1-e96e-98854eeb461d"},"source":["%cd /content/drive/My Drive/Github"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Github\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K7F_tSLlvQBG","executionInfo":{"status":"ok","timestamp":1628813020311,"user_tz":-600,"elapsed":277,"user":{"displayName":"Mitchell Stares","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVXqZWjE_TYBCDaTb8aUFX0KkvgDiMSNHzRC7xVw=s64","userId":"10987502777190906211"}}},"source":["username = 'MitchStares'\n","repository = 'DroneML'\n","git_token = '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'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OaDWLPuJvp79","executionInfo":{"status":"ok","timestamp":1628813022776,"user_tz":-600,"elapsed":809,"user":{"displayName":"Mitchell Stares","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVXqZWjE_TYBCDaTb8aUFX0KkvgDiMSNHzRC7xVw=s64","userId":"10987502777190906211"}},"outputId":"38cff6d8-b1b0-4e93-9cc1-05cc6602a9d6"},"source":["#!git clone https://{git_token}@github.com/{username}/{repository}\n","%cd {repository}\n","%ls -a\n","%cd weight_map_loss\n","%ls -a"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Github/DroneML\n","\u001b[0m\u001b[01;34mAndroid_DJI\u001b[0m/              Hakea_DroneMLDetection_Paper.pdf  \u001b[01;34mweight_map_loss\u001b[0m/\n","\u001b[01;34mbrightness_augmentation\u001b[0m/  \u001b[01;34m__pycache__\u001b[0m/\n","\u001b[01;34m.git\u001b[0m/                     README.md\n","/content/drive/My Drive/Github/DroneML/weight_map_loss\n","helpers.py  kfold_wmbl_unet.ipynb  \u001b[0m\u001b[01;34m__pycache__\u001b[0m/  \u001b[01;34munet_data_new\u001b[0m/\n","\u001b[01;34mkfold\u001b[0m/      kfold_wmbl_unet.py     README.md     wmbl_inference.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Epus5UB-yVPC","executionInfo":{"status":"ok","timestamp":1628813025628,"user_tz":-600,"elapsed":282,"user":{"displayName":"Mitchell Stares","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVXqZWjE_TYBCDaTb8aUFX0KkvgDiMSNHzRC7xVw=s64","userId":"10987502777190906211"}},"outputId":"f27b72ea-9f6e-4c95-f281-364b044aac93"},"source":["os.getcwd()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Github/DroneML/weight_map_loss'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"ojrvgi5lr-Nw","colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"status":"error","timestamp":1628812984665,"user_tz":-600,"elapsed":3469,"user":{"displayName":"Mitchell Stares","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVXqZWjE_TYBCDaTb8aUFX0KkvgDiMSNHzRC7xVw=s64","userId":"10987502777190906211"}},"outputId":"af1867db-a40a-48c0-8188-117a4f41961a"},"source":["import argparse\n","import os\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","from keras import backend as K\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from keras.layers import Activation, BatchNormalization, Dropout, Input\n","from keras.layers.convolutional import Conv2D, Conv2DTranspose\n","from keras.layers.core import Reshape\n","from keras.layers.merge import add, concatenate\n","from keras.layers.pooling import MaxPooling2D\n","from keras.models import Model\n","from tensorflow.keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import KFold, train_test_split\n","\n","from helpers import adjust_brightness, Metrics, cw_map_loss, generate_class_weighted_maps, generate_weight_maps\n","plt.style.use(\"ggplot\")"],"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-9e724254503f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madjust_brightness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw_map_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_class_weighted_maps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_weight_maps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ggplot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helpers'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"Z4Z16hr-0ViT","executionInfo":{"status":"error","timestamp":1628812969947,"user_tz":-600,"elapsed":298,"user":{"displayName":"Mitchell Stares","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVXqZWjE_TYBCDaTb8aUFX0KkvgDiMSNHzRC7xVw=s64","userId":"10987502777190906211"}},"outputId":"3737255a-22d9-4b79-d6b7-af73fdc9cc66"},"source":["%tensorflow_version 2.x\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-20c817d9d55e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorflow_version 2.x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"mwuQeNZ6r-N3"},"source":["\n","K.James 2019\n"," Trains a U-Net model using k-fold validation. \n"," This code used for MSc thesis and paper in various configurations.\n","\n","Arguments: \n"," -w : weight map weights\n"," -t : weight map edge thickness\n","\n","Images in paths: path_train = 'unet_data_new\\\\' and  path_test = 'unet_data_new\\\\test\\\\'\n","Expects images to be in 'images' folder and corresponding masks to be in 'masks' folder within each of these paths\n","Please create folder structure kfold\\output for the outputs.\n","\n","References: \n"," U-Net: O. Ronneberger, P. Fischer, and T.Brox, \"U-Net: Convolutional netowrks for biomedical image segmentation,\" \n"," in International Conference on Meidcal image computing and computer-assisted intervention. \n"," Springer, 2015, pp.234-241\n","\n","Acknowledgements: U-Net implementation based on:  https://www.depends-on-the-definition.com/unet-keras-segmenting-images/ (has MIT license)\n"]},{"cell_type":"code","metadata":{"id":"avSbU7o8r-N6","executionInfo":{"status":"ok","timestamp":1628812710137,"user_tz":-600,"elapsed":760,"user":{"displayName":"Mitchell Stares","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVXqZWjE_TYBCDaTb8aUFX0KkvgDiMSNHzRC7xVw=s64","userId":"10987502777190906211"}}},"source":["# Get and resize images and masks\n","def get_data(path, load_masks=True):  \n","    ids = os.listdir(path + \"images\") \n","    idsmasks  = os.listdir(path + \"masks\")  \n","    l = len(ids)       \n","    \n","    X = np.zeros((l, im_height, im_width, 3), dtype=np.float32)\n","   \n","    if load_masks:\n","        y = np.zeros((l, im_height, im_width, 1), dtype=np.float32)        \n","    print('Getting and resizing images ... ')\n","    for i in range(l):  \n","        \n","        image = cv2.imread(path + \"images/\" + ids[i])      \n","        x_img = cv2.resize(image,(im_height, im_width))\n","                    \n","        \n","        if load_masks:               \n","            mask = cv2.imread(path + 'masks/' + idsmasks[i],0)\n","            mask = cv2.resize(mask,(im_height, im_width))\n","            ret,mask = cv2.threshold(mask,127,255,cv2.THRESH_BINARY) #thresh to fix any px that arent quite 1 or 0 after resize\n","            mask = mask.reshape((im_height, im_width,1))\n","\n","        X[i] = x_img.squeeze() / 255\n","       \n","        if load_masks:\n","            y[i] = mask / 255\n","    print('Done!')\n","    if load_masks:\n","        return X, y\n","    else:\n","        return X\n","\n","def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n","    # first layer\n","    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n","               padding=\"same\")(input_tensor)\n","    if batchnorm:\n","        x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    # second layer\n","    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n","               padding=\"same\")(x)\n","    if batchnorm:\n","        x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    return x\n","\n","def get_weightmap_unet(n_filters=16, dropout=0.5, batchnorm=True):\n","    \n","    input_img = Input((im_height, im_width, 3), name='img')\n","    weight_map_ip = Input((im_height, im_width,1),name='map')   \n","    \n","    # contracting path\n","    \n","    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n","    p1 = MaxPooling2D((2, 2)) (c1) #stride defaults to poolsize, ie, 2.\n","    p1 = Dropout(dropout*0.5)(p1)\n","\n","    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n","    p2 = MaxPooling2D((2, 2)) (c2)\n","    p2 = Dropout(dropout)(p2)\n","\n","    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n","    p3 = MaxPooling2D((2, 2)) (c3)\n","    p3 = Dropout(dropout)(p3)\n","\n","    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n","    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n","    p4 = Dropout(dropout)(p4)\n","    \n","    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n","    \n","    # expansive path   \n","    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n","    u6 = concatenate([u6, c4])\n","    u6 = Dropout(dropout)(u6)\n","    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n","\n","    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n","    u7 = concatenate([u7, c3])\n","    u7 = Dropout(dropout)(u7)\n","    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n","\n","    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n","    u8 = concatenate([u8, c2])\n","    u8 = Dropout(dropout)(u8)\n","    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n","\n","    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n","    u9 = concatenate([u9, c1], axis=3)\n","    u9 = Dropout(dropout)(u9)\n","    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n","    \n","    outputs = Conv2D(1, (1, 1), activation='sigmoid',name=\"output\") (c9)\n","\n","    model = Model(inputs=[input_img,weight_map_ip], outputs=[outputs,weight_map_ip]) #pass weight map straight from input to output\n","    #print(model.summary())\n","    print('MODEL INPUT',model.input_shape)\n","    print(\"MODEL OUTPUT\",model.output_shape)   \n","    \n","    return model\n","\n","def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n","    # contracting path\n","    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n","    p1 = MaxPooling2D((2, 2)) (c1) #stride defaults to poolsize, ie, 2.\n","    p1 = Dropout(dropout*0.5)(p1)\n","\n","    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n","    p2 = MaxPooling2D((2, 2)) (c2)\n","    p2 = Dropout(dropout)(p2)\n","\n","    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n","    p3 = MaxPooling2D((2, 2)) (c3)\n","    p3 = Dropout(dropout)(p3)\n","\n","    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n","    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n","    p4 = Dropout(dropout)(p4)\n","    \n","    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n","    \n","    # expansive path   \n","    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n","    u6 = concatenate([u6, c4])\n","    u6 = Dropout(dropout)(u6)\n","    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n","\n","    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n","    u7 = concatenate([u7, c3])\n","    u7 = Dropout(dropout)(u7)\n","    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n","\n","    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n","    u8 = concatenate([u8, c2])\n","    u8 = Dropout(dropout)(u8)\n","    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n","\n","    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n","    u9 = concatenate([u9, c1], axis=3)\n","    u9 = Dropout(dropout)(u9)\n","    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n","    \n","    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)    \n","\n","    model = Model(inputs=[input_img], outputs=[outputs])\n","  \n","    return model"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"1KyIFEDjr-N-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628812491244,"user_tz":-600,"elapsed":273,"user":{"displayName":"Mitchell Stares","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVXqZWjE_TYBCDaTb8aUFX0KkvgDiMSNHzRC7xVw=s64","userId":"10987502777190906211"}},"outputId":"9f078cde-aa0c-48db-8cf6-ff9031e08a7f"},"source":["#   Arguments\n","ap = argparse.ArgumentParser()\n","ap.add_argument('-f')\n","ap.add_argument(\"-w\", \"--weights\", type=str, default=\"2,0.5\")\n","ap.add_argument(\"-t\", \"--thick\", type=int, default=5)\n","args = vars(ap.parse_args())\n","\n","weights =list(map(float,args[\"weights\"].split(',')))\n","\n","# Set some parameters\n","im_width = 512\n","im_height = 512\n","border = 5\n","path_train = 'unet_data_new/'\n","path_test = 'unet_data_new/test/'\n","U = weights[0] #background\n","L = weights[1] #edge\n","t = args[\"thick\"]\n","print(U,L,t)\n","#F=weights[1]\n","#L=weights[2]\n","#------------------------------------------"],"execution_count":29,"outputs":[{"output_type":"stream","text":["2.0 0.5 5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkOkk2YXyMyU","executionInfo":{"status":"ok","timestamp":1628812742512,"user_tz":-600,"elapsed":28101,"user":{"displayName":"Mitchell Stares","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVXqZWjE_TYBCDaTb8aUFX0KkvgDiMSNHzRC7xVw=s64","userId":"10987502777190906211"}},"outputId":"ac3156b5-9faf-49d1-b35b-afd29d1e8280"},"source":["#Train -------\n","X, y = get_data(path_train, load_masks=True)\n","kfold = KFold(n_splits=10, shuffle=True, random_state=42) #<----------------------------------------------------------------\n","fold = 0\n","overall_metrics = [[],[],[],[],[],[],[],[],[],[],[]]\n","names = [\"precision\",\"recall\",\"F1\",\"Dice\",\"IOU\",\"Accuracy\",\"av_precision\",\"av_recall\",\"av_F1\",\"av_Dice\",\"av_IOU\"]"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Getting and resizing images ... \n","Done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3CBfqAS8r-OB","colab":{"base_uri":"https://localhost:8080/","height":666},"executionInfo":{"status":"error","timestamp":1628812838157,"user_tz":-600,"elapsed":47920,"user":{"displayName":"Mitchell Stares","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVXqZWjE_TYBCDaTb8aUFX0KkvgDiMSNHzRC7xVw=s64","userId":"10987502777190906211"}},"outputId":"96952f93-7f29-47f8-e0a4-63f88b655d43"},"source":["#------------\n","for train_indices, val_indices in kfold.split(X, y):\n","    fold+=1\n","    print(\"\\n \\n Fold {}\".format(fold))  \n","\n","    \n","    print(train_indices.shape,val_indices.shape)\n","    if(len(train_indices)%2 !=0):\n","        train_indices = train_indices[:-1]\n","    if(len(val_indices)%2 !=0):\n","        val_indices = val_indices[:-1]\n","    print(train_indices.shape,val_indices.shape)\n","\n","    X_train = X[train_indices]\n","    y_train = y[train_indices]\n","    X_valid = X[val_indices]\n","    y_valid = y[val_indices] \n","\n","    w_train = generate_weight_maps(y_train,[U,L],t)    \n","    w_train = np.expand_dims(w_train,3)\n","\n","    #w_valid = generate_class_weighted_maps(y_valid,[U,F,L],t) \n","    w_valid = generate_weight_maps(y_valid,[U,L],t) \n","    w_valid = np.expand_dims(w_valid,3)\n","\n","    print(len(X_train),len(X_valid))\n","   \n","    model = get_weightmap_unet( n_filters=16, dropout=0.05, batchnorm=True)\n","    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n","    model.compile(optimizer=sgd, loss=cw_map_loss)\n","    \n","    \n","    data_gen_args_image = dict(horizontal_flip=True,\n","                        vertical_flip=True,\n","                        rotation_range=20,\n","                        width_shift_range=0.2,\n","                        height_shift_range=0.2,\n","                        zoom_range=0.2,\n","                        fill_mode='nearest',\n","                        preprocessing_function=adjust_brightness)\n","\n","    data_gen_args_mask = dict(horizontal_flip=True,\n","                        vertical_flip=True,\n","                        rotation_range=20,\n","                        width_shift_range=0.2,\n","                        height_shift_range=0.2,\n","                        zoom_range=0.2,\n","                        fill_mode='nearest'\n","                        )\n","   \n","    image_datagen = ImageDataGenerator(**data_gen_args_image)\n","    mask_datagen = ImageDataGenerator(**data_gen_args_mask)\n"," \n","    seed = 2019 #same seed for both as we have to distort mask in the same way\n","    bs = 2\n","\n","      \n","    #yields [X1i, X2i],yi\n","    def generator():\n","        image_generator = image_datagen.flow(X_train, seed=seed, batch_size=bs, shuffle=True)\n","        mask_generator = mask_datagen.flow(y_train, seed=seed, batch_size=bs, shuffle=True)\n","        weight_generator = mask_datagen.flow(w_train, seed=seed, batch_size=bs, shuffle=True)\n","        while True:\n","            X1i = image_generator.next()\n","            X2i = weight_generator.next()                      \n","            yi = mask_generator.next()    \n","\n","            # ---threshold arrays---keep them binary not interpolated\n","\n","            #Weights\n","            M = (U-L)/2. + L\n","            X2i[X2i < M] = L\n","            X2i[X2i >= M] = U\n","            \n","            #Masks            \n","            yi[yi < 0.5] = 0\n","            yi[yi >= 0.5] = 1              \n","            \n","            yield ([X1i, X2i],[yi,X2i])\n","   \n","    callbacks = [\n","        EarlyStopping(patience=20, verbose=1),\n","        ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n","        ModelCheckpoint('kfold/output/model-hakea{}.h5'.format(fold), verbose=1, save_best_only=True, save_weights_only=True)\n","    ]\n","   \n","    a =  [X_valid,w_valid]\n","    b =  [y_valid,w_valid]     \n","    results = model.fit_generator(generator(), steps_per_epoch=(len(X_train) // bs), epochs=2000, callbacks=callbacks, validation_data=(a,b))    \n","    \n","    plt.figure(figsize=(8, 8))\n","    plt.title(\"Learning curve\")\n","    plt.plot(results.history[\"loss\"], label=\"loss\")\n","    plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n","    plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n","    plt.xlabel(\"epochs\")\n","    plt.ylabel(\"loss\")\n","    plt.legend()\n","    plt.savefig('kfold/output/LearningCurve{}'.format(fold),bbox_inches='tight')\n","\n","    \n","\n","    #---------\n","    input_img = Input((im_height, im_width, 3), name='img')\n","    inference = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n","    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n","    inference.compile(optimizer=sgd, loss=\"binary_crossentropy\", metrics=['accuracy'])\n","\n","    inference.load_weights('kfold/output/model-hakea{}.h5'.format(fold))\n","    \n","    preds_val = inference.predict(X_valid, verbose=1)\n","    \n","    kernel = np.ones((5,5),np.uint8)\n","    preds_val_t = (preds_val > 0.5).astype(np.uint8)\n","    binary = []\n","\n","    #remove noise\n","    for i in range(0,len(preds_val_t)):\n","        im = preds_val_t[i]   \n","        \n","        im = cv2.morphologyEx(im, cv2.MORPH_OPEN, kernel)      \n","            \n","        binary.append(im)\n","   \n","           \n","    \n","    print('calculating metrics')\n","    y_valid = y_valid.astype('uint8')\n","    binary = np.array(binary)\n","    binary = binary.astype('uint8')\n","    \n","    m = Metrics(y_valid.squeeze(),binary) \n","    overall_metrics[0].append(m.precison(True))\n","    overall_metrics[1].append(m.recall(True))\n","    overall_metrics[2].append(m.f1_score(True))\n","    overall_metrics[3].append(m.dice(True))\n","    overall_metrics[4].append(m.iou(True))\n","    overall_metrics[5].append(m.accuracy(True))\n","    \n","    overall_metrics[6].append(m.precison(False))\n","    overall_metrics[7].append(m.recall(False))\n","    overall_metrics[8].append(m.f1_score(False))\n","    overall_metrics[9].append(m.dice(False))\n","    overall_metrics[10].append(m.iou(False))    \n","    \n","    f = open(\"kfold/output/{}.txt\".format(fold),\"w+\")\n","    f.write(\"           Batchwise,         Average\\n\")\n","    f.write(\"Precision {:.2f} {:.2f}\\n\".format(m.precison(True),m.precison(False)))\n","    f.write(\"Recall    {:.2f} {:.2f}\\n\".format(m.recall(True),m.recall(False)))\n","    f.write(\"F1        {:.2f} {:.2f}\\n\".format(m.f1_score(True),m.f1_score(False)))\n","    f.write(\"Dice      {:.2f} {:.2f}\\n\".format(m.dice(True),m.dice(False)))\n","    f.write(\"IOU       {:.2f} {:.2f}\\n\".format(m.iou(True),m.iou(False)))\n","    f.write(\"Accuracy  {:.2f}\\n\".format(m.accuracy()))\n","    f.close()\n","    \n","    \n","f = open(\"kfold/output/cumulative_results.txt\",\"w+\")\n","\n","print('-------------------------')\n","print('-------------------------')\n","for m in range(len(overall_metrics)):  \n","        n = names[m]       \n","        mean = np.array(overall_metrics[m])            \n","        overall_metrics[m].append(np.mean(mean)) #add so we can take mean across the folds\n","        stdev = np.std(overall_metrics[m])\n","        print(\"{}: {:.2f} +- {:.2f}\".format(n,np.mean(mean),stdev))\n","        f.write(\"{}: {:.2f} +- {:.2f}\\n\".format(n,np.mean(mean),stdev))\n","\n","print('-------------------------')\n","print('-------------------------')\n","f.close()\n"],"execution_count":34,"outputs":[{"output_type":"stream","text":["\n"," \n"," Fold 1\n","(66,) (8,)\n","(66,) (8,)\n","66 8\n","MODEL INPUT [(None, 512, 512, 3), (None, 512, 512, 1)]\n","MODEL OUTPUT [(None, 512, 512, 1), (None, 512, 512, 1)]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n","/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/2000\n"," 1/33 [..............................] - ETA: 20:12 - loss: -52.3628 - output_loss: 0.0300 - map_loss: -52.3927"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-a338ba443b8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"SydE68RPz8IN"},"source":["# New Section"]}]}